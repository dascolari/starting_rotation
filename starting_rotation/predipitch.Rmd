---
title: "Predi-Pitch: Snack on This Curve Whenever You Want"
author: "David Scolari, Harrison Snell, Brandon Williams"
date: "4/13/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(here)
path <- here()

source(file.path(path, 'code', 'dugout.R'))

load(file = file.path(path, 'output', 'tables', "overall_performance_all.RDs"))


foreach(id = 1:30) %do% {
  # make filenames according to loop index
  fname_type <- paste0("types", id, ".RDs")
  fname_zones <- paste0("zones", id, ".RDs")
  fname_bypitch <- paste0("by_pitch_performance", id, ".RDs")

  # load table outputs according to loop index
  load(file = file.path(path, 'output', 'tables', fname_type))
  load(file = file.path(path, 'output', 'tables', fname_zones))
  load(file = file.path(path, 'output', 'tables', fname_bypitch))
  }
```

## Introduction
Hitting a baseball has been shown to be one of the most difficult tasks in all of sports. Anybody who has gone to a batting cage and tried the fastest machine for fun knows how hard it can be to hit a normal fastball. That does not even include the possibilities of breaking balls and off-speed pitches. Batters have a fraction of a fraction of a second to recognize a pitch, determine if that pitch will be a ball or a strike, and set their swing into motion. Considering the human body can only move so fast to get the bat over the plate, the batter has to make their decision moments after the ball leaves the pitcher's hand. At that point, even some professional baseball players have to guess on whether they are facing a changeup or a fastball or a curveball. Any additional information the batter can have is crucial. The goal of our model is to provide some of that additional information.

Pitch predicting is a very important part of baseball. So important that teams will do almost anything for insight on what the opposing team's pitcher is going to throw. Other than illicit methods, hitters are trained to use information on a pitcher's previous pitch throwing behvior to guess which pitch is coming next. We can model this deciscion making process with machine learning techniques. 

By modeling pitch prediction, we can learn what information is relevant to a pitcher's pitch selection. We can also better understand what makes a pitcher more unpredictable than other. It's gonna be good

In the following report will talk about why pitches are different, share evidence that pitchers have different strategies from at bat to at bat, and describe the engineering of our model, which is basically a trashcan .

## Why do we care about a pitch?

Not all pitches are made the same. From sliders to cutters to knuckleballs, each pitch tends to have its own characteristics that define it. 


```{r}
library(lemon)
knit_print.data.frame <- lemon_print

harrison_path = "C:/Users/Student/Documents/School/University of Texas-Austin/Classes/Data Mining/starting_rotation/starting_rotation"

load(file.path(path, "output", "pitches_import.RData"))

```

```{r, render=lemon_print}
pitch_sum = pitches %>%
  filter(pitch_type != "") %>%
  filter(pitch_type != "IN")%>%
  dplyr::select(pitch_type,px,pz,start_speed,end_speed,spin_rate,spin_dir,break_angle,break_length,break_y)%>%
  mutate(pitch_type = as.factor(pitch_type))%>%
  group_by(pitch_type)%>%
  summarise(across(where(is.numeric), ~ mean(.x, na.rm = TRUE)))

pitch_sum

```

```{r}
plot_data = pitches %>%
  filter(pitch_type != "") %>%
  filter(pitch_type != "IN")%>%
  dplyr::select(pitcher_id,pitch_type,px,pz,start_speed,end_speed,spin_rate,spin_dir,break_angle,break_length,break_y)

plot_data$pitch_type = as.factor(plot_data$pitch_type)

plot_archer = plot_data%>%
  filter(pitcher_id == 502042)

plot_arrieta = plot_data %>%
  filter(pitcher_id == 453562)

plot_greinke = plot_data %>%
  filter(pitcher_id == 425844)

ggplot(plot_archer)+
  geom_point(aes(x=spin_rate,y=spin_dir,color=pitch_type),alpha=.2)

ggplot(plot_archer)+
  geom_point(aes(x=break_angle,y=break_length,color=pitch_type),alpha=.2)

ggplot(plot_arrieta)+
  geom_point(aes(x=spin_rate,y=spin_dir,color=pitch_type),alpha=.2)

ggplot(plot_arrieta)+
  geom_point(aes(x=break_angle,y=break_length,color=pitch_type),alpha=.2)

ggplot(plot_greinke)+
  geom_point(aes(x=spin_rate,y=spin_dir,color=pitch_type),alpha=.2)

ggplot(plot_greinke)+
  geom_point(aes(x=break_angle,y=break_length,color=pitch_type),alpha=.2)



```

So to some degree we have established that each pitch has a unique set of characteristics for the most part. However, this set of characteristics is also unique to each pitcher.

```{r}

plot_all = plot_data%>%
  filter(pitcher_id == 502042 || pitcher_id == 453562 || pitcher_id == 425844)

ggplot(plot_all)+
  geom_point(aes(x=spin_rate,y=spin_dir,color=pitch_type),alpha=.2)

```

## Pichers be sequencing
AB networks

## Our Random Forrest 
describe the features, describe the dream 
Brief description of the features in each model
 - since I made the models, it might be easiest if I do this(david)
 - but generally, trashcan_1 is situation info, trashcan_2 is lagged pitches and event results, trashcan_3 is addition of "game level fixed effects" type info
 
Look at the tables generated in the appendix and write about any patterns you see. For example, some pitchers get better with each addition of features, some get better with the first addition but worse with the second addition, some get worse with each addition of features. 

Also look at the by pitch performance. Seems like there's a tradeoff between accuracy with the pitcher's most frequent pitch and accuracy with some of the secondary pitches. Is there something about the pitchers that explains these patterns? (we probably can't say definitively why this is, but we can suggest reasons)


### The Data
(Feel free to relocate this to where it makes the most sense.)

The data involved in this project consists of every pitch from the 2015 through the 2018 Major League Baseball (MLB) seasons. These four seasons contained nearly 3 million observations, and the data include categorization of 16 different types of pitches, the spin, speed, and location of each pitch, the game situation (score, runners on base, balls and strikes, etc.), information about the pitcher and batter, and the result of the at-bat. 

(Gonna add a description of some of the built features here to make them easier to talk about in a later section)

### Methodology

(David, supplement these descriptions with further details as needed.)

Given how difficult it is to get hits consistently at the major league level, having an idea an idea of what the opposing pitcher is about to throw would confer a significant advantage to the hitter. We endeavor to create a model that successfully predicts the next pitch a pitcher will throw in an at-bat, given the circumstances of the at-bat, the tendencies of the pitcher, and the progress of the game up to that point. Using three distinct random forest models, we derive a predictive approach that generally outperforms guessing that the pitcher will throw their most common pitch (often called "sitting on a pitch"), and in most cases, significantly exceeds this "sitting on a pitch" approach.

The models are generated with a train/test split and then evaluated for the out-of-sample performance against the testing set. Models are generated per pitcher, in such a way that be beneficial in application to a baseball manager or hitter, given the situation in the game. 

#### The Situational Model

The first of our three random forest models uses information readily available in the at-bat to predict the upcoming pitch. The features involved here include the ball-strike count, opposing batter's stance, inning, how many pitches thrown in the at-bat so far, the game score, and the runners on base. This is the most interpretable model, as it is composed of the factors that are generally considered most relevant and well-known by players and coaches in the moment. As random forests are an aggregation of individual trees, it can be illustrative to look at a single tree to get a sense for how decisions are being made at various nodes. Consider, for example, the following tree as an example of what the random forest is doing for pitcher Felix Hernandez. 

```{r}

## Load in data
set.seed(117) #set seed for image replication 

load(file.path(path, "output", "pitches_import.RData"))

## Felix Hernandez Example ID 2

id = 2

fname_pitcher <- paste0("pitcher", id, ".Rds")
load(file = file.path(path, 'output', 'pitchers', fname_pitcher))

fname_factor <- paste0("pitcher_factor", id, ".RDs")
load(file = file.path(path, 'output', 'pitchers', fname_factor))

pitcher_first <- names$first_name[id]
pitcher_last <- names$last_name[id]

## Train / Test

pitcher_split =  initial_split(pitcher, prop=0.8)
pitcher_train = training(pitcher_split)
pitcher_test  = testing(pitcher_split)

## Single tree and 1SE Prune

pitcher.tree = rpart(pitch_type ~ 
                       inning + 
                       b_count + 
                       s_count +
                       pitch_num +
                       stand +
                       on_1b + 
                       on_2b + 
                       on_3b +
                       outs +
                       p_score +
                       b_score,
                     data=pitcher_train,
                     control = rpart.control(cp = .005, minsplit = 30))

prune_1se = function(my_tree) {
  out = as.data.frame(my_tree$cptable)
  thresh = min(out$xerror + out$xstd)
  cp_opt = max(out$CP[out$xerror <= thresh])
  prune(my_tree, cp=cp_opt)
}

pitcher.tree_prune = prune_1se(pitcher.tree)

## Plot

rpart.plot(pitcher.tree_prune, type=4, extra=1)


```

Hernandez is a pitcher with a diverse arsenal of pitches. As one can see, the predictive model analyzes factors about the game situation to indicate the next pitch. It considers, for example, the count on the batter and whether the batter stands left or right. After running through the branches and nodes with binary decisions based on the in-game situation, a prediction about the next pitch is made at the bottom of the tree. The random forest takes a bootstrap aggregate of trees like this one, but a single tree helps us see an example of the predictive process. 

#### The Lagged Model

The second random forest builds upon the features selected in the Situational Model and supplements them with information about the previous two pitches and the event the last at-bat. This allows for the model to incorporate lagged information that might directly influence the next pitch. Did the pitcher just give up a home run on the curve? Maybe it's a steady diet of fastballs from here on out. Did the pitcher just give the batter two straight fastballs to study? Perhaps it's time for an off-speed pitch like a change-up. 

#### Trash Can Model

The third and final random forest uses nearly every feature from the dataset to control for all possible scenarios and variations in the feature matrix. This means that it not only considers all the factors included in the other two models, but also includes what the pitcher's game has looked like so far; that is, it takes into account the pitch choices as a percent of the overall pitches in the game up to that point. (Is this a correct reading?) So if the pitcher is leaning heavily on the slider that day, this model will incorporate that pattern. 

## Results

In [TABLE/APPENDIX], we publish our models' results for 30 pitchers from Major League Baseball. These pitchers are generally considered some of the best in the business, but there are some pitchers from outside the top tier for completeness. We also note that the model is easily adaptable to any pitcher who threw between 2015 and 2018. In [TABLE/APPENDIX], we present the pitching profiles of the 30 pitchers based on the style of their pitches and the frequency that they are thrown.  

To measure our models' effectiveness, we compare them to the most-common pitch thrown by the pitcher (called "sitONE") and to each other. The out-of-sample performance of each model is presented in "trashcans" 1 to 3 (our sincerest apologies to Astros fans for the name). 

Most models improved on the guess of the upcoming pitch when compared to the "sitting on the pitch" as seen in [TABLE/APPENDIX]. Consider the case of Chris Sale. Sale is a perennial All-Star, and finished top-5 in Cy Young (MLB's most valuable pitcher award) votes each year of our data. If a batter were to look for his most common pitch (the two-seam fastball), he would would only be right about one third of the time. However, Sale becomes increasingly more predictable as the model incorporates more features. The Situational Model and the Lagged Model predict his next pitch at 37% and 38% respectively. Still, the Game Fixed Effects Model predicts his next pitch with an out-of-sample accuracy of nearly 46%, a jump of about 13%. There isn't a hitter in baseball who wouldn't want to know Sale's next pitch with a 13% increase in accuracy!

(Do these numbers need to be responsive to different train/test splits?)
I think it'd be nice, but I think it counts as unfeasible for our computing power purposes since running the models once takes me about 30 minutes for me at least. But for interpretation purposes, small difference in performance might not be stable results so they shouldn't be read into too much. 

On the other hand, some pitcher profiles grew in accuracy only up through the first or second model, and then decrease as more features are added. For example, Mark Melancon and Huston Street have out-of-sample prediction accuracies that peak in the Lagged Model but fall in the Game Fixed Effects Model. We present this as some evidence of over-fitting for certain pitchers. 

Not all pitchers are particularly predictable, however. Corey Kluber, a two-time Cy Young winner (one time in our data window), has such a varied arsenal of pitches that even the most predictive model (.343 out of sample accuracy) barely little information about the next pitch, even if it beats he sit-one rate. Further, some pitchers remained elusive for all three of the models. Trevor Rosenthal, for instance, throws a fastball on 75% of his pitches, and all three models performed worse than this "sitting on the pitch" rate. [Do we have a good reason for why this might be happening?]


Finally, we note that predictive power does not necessarily equate to hits. Enter Zack Britton, who led the league in saves during the 2016 season. Britton is nearly a one-pitch pitcher, throwing sinkers on 89.7% of his pitches. The Game Fixed Effects model improves this prediction a few fractions of a percent, but in either case, it's fair to say that most hitters know exactly what Britton is about to throw. Nevertheless, Britton put up an otherworldly 0.54 ERA in 2016! That is to say, even if batters knew with near perfect clairvoyance a that sinker was on its way, making contact that leads to a hit is a whole other matter. 



## what it all means, probably nothing 

implications for how hitters should approach thinking about predicting pitches. 

## Appendix
```{r tables, include=TRUE}
overall_performance_all

types_Trevor_Rosenthal
types_Felix_Hernandez
types_Chris_Archer
types_Zach_Britton
types_Wade_Davis
types_Dallas_Keuchel
types_Corey_Kluber
types_Luke_Gregerson
types_David_Price
types_Max_Scherzer
types_Aroldis_Chapman
types_Clayton_Kershaw
types_Madison_Bumgarner
types_Sonny_Gray
types_Huston_Street
types_Brad_Boxberger
types_Zack_Greinke
types_Shawn_Tolleson
types_Jordan_Zimmermann
types_Jacob_deGrom
types_Gerrit_Cole
types_Mark_Melancon
types_Jake_Arrieta
types_Andrew_Miller
types_Stephen_Strasburg
types_Collin_McHugh
types_Michael_Wacha
types_Chris_Sale
types_Zack_Greinke
types_Yu_Darvish

by_pitch_performance_Trevor_Rosenthal
by_pitch_performance_Felix_Hernandez
by_pitch_performance_Chris_Archer
by_pitch_performance_Zach_Britton
by_pitch_performance_Wade_Davis
by_pitch_performance_Dallas_Keuchel
by_pitch_performance_Corey_Kluber
by_pitch_performance_Luke_Gregerson
by_pitch_performance_David_Price
by_pitch_performance_Max_Scherzer
by_pitch_performance_Aroldis_Chapman
by_pitch_performance_Clayton_Kershaw
by_pitch_performance_Madison_Bumgarner
by_pitch_performance_Sonny_Gray
by_pitch_performance_Huston_Street
by_pitch_performance_Brad_Boxberger
by_pitch_performance_Zack_Greinke
by_pitch_performance_Shawn_Tolleson
by_pitch_performance_Jordan_Zimmermann
by_pitch_performance_Jacob_deGrom
by_pitch_performance_Gerrit_Cole
by_pitch_performance_Mark_Melancon
by_pitch_performance_Jake_Arrieta
by_pitch_performance_Andrew_Miller
by_pitch_performance_Stephen_Strasburg
by_pitch_performance_Collin_McHugh
by_pitch_performance_Michael_Wacha
by_pitch_performance_Chris_Sale
by_pitch_performance_Zack_Greinke
by_pitch_performance_Yu_Darvish

```